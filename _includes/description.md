<!-- How do we solve the large-scale problems of science quickly on modern
computers?  How do we measure the performance of new or existing simulation
codes, and what things can we do to make them run faster?  How can we best take
advantage of features like multicore processors, vector units, and graphics
co-processors?  These are the types of questions we will address in
CS 5220, Applications of Parallel Computers.  Topics include:

 - Single-processor architecture, caches, and serial performance tuning
 - Basics of parallel machine organization
 - Distributed memory programming with MPI
 - Shared memory programming with OpenMP
 - Parallel patterns: data partitioning, synchronization, and load balancing
 - Examples of parallel numerical algorithms
 - Applications from science and engineering

Because our examples will be drawn primarily from engineering and
scientific computations, we will assume some prior exposure to
numerical methods.  Students should also be able to read and write
serial programs written in C or a related language like C++ or Java.
Prior exposure to parallel programming is not required, and non-CS
students from fields involving simulation are particularly welcome!
 -->
